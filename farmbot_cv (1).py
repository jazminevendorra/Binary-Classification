try:
    print("SCRIPT STARTED")
    # -*- coding: utf-8 -*-
    """Farmbot CV.ipynb
    
    Automatically generated by Colab.
    
    Original file is located at
        https://colab.research.google.com/drive/1up2qqvKI8oMTE_tSkF9OSFNU4b5bvsqQ
    
    # To install database (from kaggle)
    """
    
    import os
    
    """# Binary segmentation of data into healthy and non-healthy"""
    
    import shutil
    import random
    
    # Define source and target directories
    source_dir = "Lettuce_disease_datasets"
    train_dir = "train"
    validation_dir = "validation"
    test_dir = "test"
    
    # Create directories for binary classification.
    # Basicamente crea los folders para poner las imagenes clasificadas.
    os.makedirs(f"{train_dir}/healthy", exist_ok=True)
    os.makedirs(f"{train_dir}/non_healthy", exist_ok=True)
    os.makedirs(f"{validation_dir}/healthy", exist_ok=True)
    os.makedirs(f"{validation_dir}/non_healthy", exist_ok=True)
    os.makedirs(f"{test_dir}/healthy", exist_ok=True)
    os.makedirs(f"{test_dir}/non_healthy", exist_ok=True)
    
    # Split the dataset into train, validation, and test sets
    healthy_classes = ["Healthy"]  # Specify the class for healthy lettuce
    
    # Go through the files
    for disease_class in os.listdir(source_dir):
        disease_class_path = os.path.join(source_dir, disease_class)
        if os.path.isdir(disease_class_path):
            images = os.listdir(disease_class_path)
            random.shuffle(images)
    
            train_split = int(0.8 * len(images))
            val_split = int(0.9 * len(images))
    
            # Determine target class (healthy or non_healthy)
            target_class = "healthy" if disease_class in healthy_classes else "non_healthy"
    
            # Move images to respective directories
            for img in images[:train_split]:
                shutil.copy(os.path.join(disease_class_path, img), f"{train_dir}/{target_class}")
            for img in images[train_split:val_split]:
                shutil.copy(os.path.join(disease_class_path, img), f"{validation_dir}/{target_class}")
            for img in images[val_split:]:
                shutil.copy(os.path.join(disease_class_path, img), f"{test_dir}/{target_class}")
    
    """# Data generators"""
    
    from tensorflow.keras.preprocessing.image import ImageDataGenerator
    
    print("[4] Dataset split complete. About to create data generators...")
    print("About to create data generators...")
    # Data augmentation applied to the training set (data normalization)
    train_datagen = ImageDataGenerator(
        rescale=1.0/255,              # Normalize pixel values to [0, 1]
        rotation_range=40,            # Randomly rotate images by up to 40 degrees
        width_shift_range=0.2,        # Randomly shift images horizontally by 20% of width
        height_shift_range=0.2,       # Randomly shift images vertically by 20% of height
        shear_range=0.2,              # Randomly shear images
        zoom_range=0.2,               # Randomly zoom in on images
        horizontal_flip=True,         # Randomly flip images horizontally
        brightness_range=[0.8, 1.2],  # Randomly adjust brightness
        fill_mode='nearest'           # Fill in missing pixels after transformations
    )
    
    # Validation and test sets only rescale images (no augmentation)
    validation_datagen = ImageDataGenerator(rescale=1.0/255)
    test_datagen = ImageDataGenerator(rescale=1.0/255)
    
    # Create generators
    train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(150, 150),
        batch_size=32,
        class_mode='binary'  # Binary classification
    )
    
    validation_generator = validation_datagen.flow_from_directory(
        validation_dir,
        target_size=(150, 150),
        batch_size=32,
        class_mode='binary'
    )
    
    test_generator = test_datagen.flow_from_directory(
        test_dir,
        target_size=(150, 150),
        batch_size=32,
        class_mode='binary',
        shuffle=False
    )
    print("[5] Data generators created.")
    
    print("About to define model...")
except Exception as e:
    import traceback
    print("ERROR OCCURRED:")
    traceback.print_exc()

"""# Data generators"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Data augmentation applied to the training set (data normalization)
train_datagen = ImageDataGenerator(
    rescale=1.0/255,              # Normalize pixel values to [0, 1]
    rotation_range=40,            # Randomly rotate images by up to 40 degrees
    width_shift_range=0.2,        # Randomly shift images horizontally by 20% of width
    height_shift_range=0.2,       # Randomly shift images vertically by 20% of height
    shear_range=0.2,              # Randomly shear images
    zoom_range=0.2,               # Randomly zoom in on images
    horizontal_flip=True,         # Randomly flip images horizontally
    brightness_range=[0.8, 1.2],  # Randomly adjust brightness
    fill_mode='nearest'           # Fill in missing pixels after transformations
)

# Validation and test sets only rescale images (no augmentation)
validation_datagen = ImageDataGenerator(rescale=1.0/255)
test_datagen = ImageDataGenerator(rescale=1.0/255)

# Create generators
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary'  # Binary classification
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
"""TEST"""


from PIL import Image
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt



# Function to classify an uploaded image
def classify_uploaded_image(model, img_path):
    # Load the image using Pillow (PIL)
    img = Image.open(img_path).convert('RGB')  # Convert to RGB to ensure 3 channels
    img = img.resize((150, 150))  # Resize to model's input size
    img_array = np.array(img)  # Convert image to NumPy array
    img_array = img_array / 255.0  # Normalize pixel values to [0, 1]
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

    # Make predictions
    prediction = model.predict(img_array)
    if prediction[0] > 0.5:
        result = "Non-Healthy"
        confidence = prediction[0][0] * 100
    else:
        result = "Healthy"
        confidence = (1 - prediction[0][0]) * 100

    # Display the image and prediction
    plt.imshow(img)
    plt.axis('off')
    plt.title(f"Predicted: {result} ({confidence:.2f}% confidence)")
    plt.show()

    print(f"The uploaded lettuce is classified as: {result}")
    print(f"Confidence score: {confidence:.2f}%")

# Classify the uploaded image
classify_uploaded_image(model, "path_to_your_image.jpg")